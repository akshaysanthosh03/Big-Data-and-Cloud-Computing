{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e5a2cb5-c5a5-46ac-a565-43d1f6bdc947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\aksha\\anaconda3\\lib\\site-packages (4.1.1)\n",
      "Requirement already satisfied: py4j<0.10.9.10,>=0.10.9.7 in c:\\users\\aksha\\anaconda3\\lib\\site-packages (from pyspark) (0.10.9.9)\n",
      "Requirement already satisfied: findspark in c:\\users\\aksha\\anaconda3\\lib\\site-packages (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "# cell_1_install_pyspark.py\n",
    "!pip install pyspark\n",
    "!pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "792131eb-a4c7-4a86-92d0-77d145b8960a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data generated\n"
     ]
    }
   ],
   "source": [
    "# generate_retail_data.py\n",
    "import csv\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import uuid\n",
    "\n",
    "# Configuration\n",
    "NUM_TRANSACTIONS = 10000\n",
    "NUM_CUSTOMERS = 500\n",
    "NUM_PRODUCTS = 200\n",
    "NUM_STORES = 50\n",
    "\n",
    "# Generate product categories\n",
    "categories = ['Electronics', 'Clothing', 'Food', 'Home & Garden', 'Sports', 'Books', 'Toys', 'Beauty']\n",
    "products = []\n",
    "\n",
    "for i in range(1, NUM_PRODUCTS + 1):\n",
    "    category = random.choice(categories)\n",
    "    price = round(random.uniform(5.99, 499.99), 2)\n",
    "    products.append({\n",
    "        'product_id': f'P{str(i).zfill(5)}',\n",
    "        'product_name': f'Product_{i}',\n",
    "        'category': category,\n",
    "        'unit_price': price,\n",
    "        'supplier_id': f'SUP{random.randint(1, 50):03d}'\n",
    "    })\n",
    "\n",
    "# Generate customers\n",
    "customers = []\n",
    "for i in range(1, NUM_CUSTOMERS + 1):\n",
    "    customers.append({\n",
    "        'customer_id': f'C{str(i).zfill(6)}',\n",
    "        'loyalty_tier': random.choice(['Bronze', 'Silver', 'Gold', 'Platinum']),\n",
    "        'join_date': (datetime.now() - timedelta(days=random.randint(1, 1000))).strftime('%Y-%m-%d'),\n",
    "        'region': random.choice(['North', 'South', 'East', 'West', 'Central'])\n",
    "    })\n",
    "\n",
    "# Generate stores\n",
    "stores = []\n",
    "regions = ['North', 'South', 'East', 'West', 'Central']\n",
    "for i in range(1, NUM_STORES + 1):\n",
    "    region = random.choice(regions)\n",
    "    stores.append({\n",
    "        'store_id': f'S{str(i).zfill(3)}',\n",
    "        'region': region,\n",
    "        'size': random.choice(['Small', 'Medium', 'Large']),\n",
    "        'online_store': random.choice([True, False])\n",
    "    })\n",
    "\n",
    "# Generate transactions\n",
    "transactions = []\n",
    "start_date = datetime(2023, 1, 1)\n",
    "end_date = datetime(2024, 1, 1)\n",
    "\n",
    "for i in range(1, NUM_TRANSACTIONS + 1):\n",
    "    transaction_date = start_date + timedelta(\n",
    "        days=random.randint(0, (end_date - start_date).days),\n",
    "        hours=random.randint(0, 23),\n",
    "        minutes=random.randint(0, 59)\n",
    "    )\n",
    "    \n",
    "    customer = random.choice(customers)\n",
    "    store = random.choice(stores)\n",
    "    num_items = random.randint(1, 5)\n",
    "    \n",
    "    transaction_total = 0\n",
    "    for item_num in range(num_items):\n",
    "        product = random.choice(products)\n",
    "        quantity = random.randint(1, 3)\n",
    "        line_total = product['unit_price'] * quantity\n",
    "        transaction_total += line_total\n",
    "        \n",
    "        transactions.append({\n",
    "            'transaction_id': f'T{str(i).zfill(8)}-{item_num+1}',\n",
    "            'transaction_date': transaction_date.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'customer_id': customer['customer_id'],\n",
    "            'store_id': store['store_id'],\n",
    "            'product_id': product['product_id'],\n",
    "            'quantity': quantity,\n",
    "            'unit_price': product['unit_price'],\n",
    "            'line_total': round(line_total, 2),\n",
    "            'payment_method': random.choice(['Credit Card', 'Debit Card', 'Cash', 'Mobile Payment'])\n",
    "        })\n",
    "\n",
    "# Write to CSV files\n",
    "# Products\n",
    "with open('products.csv', 'w', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=['product_id', 'product_name', 'category', 'unit_price', 'supplier_id'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(products)\n",
    "\n",
    "# Customers\n",
    "with open('customers.csv', 'w', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=['customer_id', 'loyalty_tier', 'join_date', 'region'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(customers)\n",
    "\n",
    "# Stores\n",
    "with open('stores.csv', 'w', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=['store_id', 'region', 'size', 'online_store'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(stores)\n",
    "\n",
    "# Transactions\n",
    "with open('transactions.csv', 'w', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=['transaction_id', 'transaction_date', 'customer_id', 'store_id', \n",
    "                                          'product_id', 'quantity', 'unit_price', 'line_total', 'payment_method'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(transactions)\n",
    "\n",
    "print(\"Data generation complete!\")\n",
    "print(f\"Generated {len(products)} products\")\n",
    "print(f\"Generated {len(customers)} customers\")\n",
    "print(f\"Generated {len(stores)} stores\")\n",
    "print(f\"Generated {len(transactions)} transaction lines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d84980f-9874-4d28-a519-0f191c93ec52",
   "metadata": {},
   "outputs": [],
   "source": [
    "-- setup_retailchain_hive.sql\n",
    "\n",
    "-- Create database\n",
    "CREATE DATABASE IF NOT EXISTS retailchain_analytics\n",
    "COMMENT 'RetailChain Big Data Analytics Database'\n",
    "LOCATION '/user/hive/warehouse/retailchain_analytics.db';\n",
    "\n",
    "USE retailchain_analytics;\n",
    "\n",
    "-- Set Hive optimization properties\n",
    "SET hive.exec.dynamic.partition=true;\n",
    "SET hive.exec.dynamic.partition.mode=nonstrict;\n",
    "SET hive.exec.max.dynamic.partitions=1000;\n",
    "SET hive.exec.max.dynamic.partitions.pernode=100;\n",
    "SET hive.enforce.bucketing=true;\n",
    "SET hive.mapred.mode=nonstrict;\n",
    "SET hive.optimize.sort.dynamic.partition=true;\n",
    "\n",
    "-- Create external tables for raw data\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS raw_products (\n",
    "    product_id STRING,\n",
    "    product_name STRING,\n",
    "    category STRING,\n",
    "    unit_price FLOAT,\n",
    "    supplier_id STRING\n",
    ")\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY ','\n",
    "STORED AS TEXTFILE\n",
    "LOCATION '/user/hive/warehouse/retailchain_analytics.db/raw_products'\n",
    "TBLPROPERTIES (\"skip.header.line.count\"=\"1\");\n",
    "\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS raw_customers (\n",
    "    customer_id STRING,\n",
    "    loyalty_tier STRING,\n",
    "    join_date STRING,\n",
    "    region STRING\n",
    ")\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY ','\n",
    "STORED AS TEXTFILE\n",
    "LOCATION '/user/hive/warehouse/retailchain_analytics.db/raw_customers'\n",
    "TBLPROPERTIES (\"skip.header.line.count\"=\"1\");\n",
    "\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS raw_stores (\n",
    "    store_id STRING,\n",
    "    region STRING,\n",
    "    size STRING,\n",
    "    online_store STRING\n",
    ")\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY ','\n",
    "STORED AS TEXTFILE\n",
    "LOCATION '/user/hive/warehouse/retailchain_analytics.db/raw_stores'\n",
    "TBLPROPERTIES (\"skip.header.line.count\"=\"1\");\n",
    "\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS raw_transactions (\n",
    "    transaction_id STRING,\n",
    "    transaction_date STRING,\n",
    "    customer_id STRING,\n",
    "    store_id STRING,\n",
    "    product_id STRING,\n",
    "    quantity INT,\n",
    "    unit_price FLOAT,\n",
    "    line_total FLOAT,\n",
    "    payment_method STRING\n",
    ")\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY ','\n",
    "STORED AS TEXTFILE\n",
    "LOCATION '/user/hive/warehouse/retailchain_analytics.db/raw_transactions'\n",
    "TBLPROPERTIES (\"skip.header.line.count\"=\"1\");\n",
    "\n",
    "-- Load data into external tables\n",
    "LOAD DATA LOCAL INPATH 'products.csv' OVERWRITE INTO TABLE raw_products;\n",
    "LOAD DATA LOCAL INPATH 'customers.csv' OVERWRITE INTO TABLE raw_customers;\n",
    "LOAD DATA LOCAL INPATH 'stores.csv' OVERWRITE INTO TABLE raw_stores;\n",
    "LOAD DATA LOCAL INPATH 'transactions.csv' OVERWRITE INTO TABLE raw_transactions;\n",
    "\n",
    "-- Create optimized tables for analytics\n",
    "-- Partitioned and bucketed fact table for transactions\n",
    "CREATE TABLE IF NOT EXISTS fact_transactions (\n",
    "    transaction_id STRING,\n",
    "    customer_id STRING,\n",
    "    store_id STRING,\n",
    "    product_id STRING,\n",
    "    quantity INT,\n",
    "    unit_price FLOAT,\n",
    "    line_total FLOAT,\n",
    "    payment_method STRING,\n",
    "    transaction_hour INT\n",
    ")\n",
    "PARTITIONED BY (transaction_year INT, transaction_month INT, transaction_day INT)\n",
    "CLUSTERED BY (customer_id) INTO 8 BUCKETS\n",
    "STORED AS PARQUET\n",
    "TBLPROPERTIES ('parquet.compression'='SNAPPY');\n",
    "\n",
    "-- Dimension tables optimized for querying\n",
    "CREATE TABLE IF NOT EXISTS dim_customer (\n",
    "    customer_id STRING,\n",
    "    loyalty_tier STRING,\n",
    "    join_date DATE,\n",
    "    region STRING,\n",
    "    customer_tenure_days INT\n",
    ")\n",
    "STORED AS PARQUET\n",
    "TBLPROPERTIES ('parquet.compression'='SNAPPY');\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS dim_product (\n",
    "    product_id STRING,\n",
    "    product_name STRING,\n",
    "    category STRING,\n",
    "    unit_price FLOAT,\n",
    "    supplier_id STRING,\n",
    "    price_range STRING\n",
    ")\n",
    "STORED AS PARQUET\n",
    "TBLPROPERTIES ('parquet.compression'='SNAPPY');\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS dim_store (\n",
    "    store_id STRING,\n",
    "    region STRING,\n",
    "    size STRING,\n",
    "    online_store BOOLEAN\n",
    ")\n",
    "STORED AS PARQUET\n",
    "TBLPROPERTIES ('parquet.compression'='SNAPPY');\n",
    "\n",
    "-- Transform and load data into optimized tables\n",
    "-- Populate dim_customer\n",
    "INSERT OVERWRITE TABLE dim_customer\n",
    "SELECT \n",
    "    customer_id,\n",
    "    loyalty_tier,\n",
    "    TO_DATE(join_date) as join_date,\n",
    "    region,\n",
    "    DATEDIFF(CURRENT_DATE(), TO_DATE(join_date)) as customer_tenure_days\n",
    "FROM raw_customers;\n",
    "\n",
    "-- Populate dim_product with derived columns\n",
    "INSERT OVERWRITE TABLE dim_product\n",
    "SELECT \n",
    "    product_id,\n",
    "    product_name,\n",
    "    category,\n",
    "    unit_price,\n",
    "    supplier_id,\n",
    "    CASE \n",
    "        WHEN unit_price < 50 THEN 'Budget'\n",
    "        WHEN unit_price >= 50 AND unit_price < 200 THEN 'Mid-Range'\n",
    "        ELSE 'Premium'\n",
    "    END as price_range\n",
    "FROM raw_products;\n",
    "\n",
    "-- Populate dim_store\n",
    "INSERT OVERWRITE TABLE dim_store\n",
    "SELECT \n",
    "    store_id,\n",
    "    region,\n",
    "    size,\n",
    "    CASE WHEN online_store = 'True' THEN true ELSE false END as online_store\n",
    "FROM raw_stores;\n",
    "\n",
    "-- Populate fact_transactions with partitioning\n",
    "INSERT OVERWRITE TABLE fact_transactions \n",
    "PARTITION (transaction_year, transaction_month, transaction_day)\n",
    "SELECT \n",
    "    t.transaction_id,\n",
    "    t.customer_id,\n",
    "    t.store_id,\n",
    "    t.product_id,\n",
    "    t.quantity,\n",
    "    t.unit_price,\n",
    "    t.line_total,\n",
    "    t.payment_method,\n",
    "    HOUR(t.transaction_date) as transaction_hour,\n",
    "    YEAR(t.transaction_date) as transaction_year,\n",
    "    MONTH(t.transaction_date) as transaction_month,\n",
    "    DAY(t.transaction_date) as transaction_day\n",
    "FROM raw_transactions t;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31c03452-2de5-4f2b-b41b-24d1d94679a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Cell 3: Create and use database\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m spark\u001b[38;5;241m.\u001b[39msql(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCREATE DATABASE IF NOT EXISTS retailchain_analytics\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m spark\u001b[38;5;241m.\u001b[39msql(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSE retailchain_analytics\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing database: retailchain_analytics\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "-- retailchain_analytics_queries.sql\n",
    "\n",
    "USE retailchain_analytics;\n",
    "\n",
    "-- Query 1: Sales Performance by Region and Category\n",
    "-- This helps identify top-performing regions and product categories\n",
    "SELECT \n",
    "    ds.region,\n",
    "    dp.category,\n",
    "    COUNT(DISTINCT ft.transaction_id) as num_transactions,\n",
    "    SUM(ft.quantity) as total_units_sold,\n",
    "    ROUND(SUM(ft.line_total), 2) as total_revenue,\n",
    "    ROUND(AVG(ft.line_total), 2) as avg_transaction_value,\n",
    "    RANK() OVER (PARTITION BY ds.region ORDER BY SUM(ft.line_total) DESC) as category_rank_in_region\n",
    "FROM fact_transactions ft\n",
    "JOIN dim_store ds ON ft.store_id = ds.store_id\n",
    "JOIN dim_product dp ON ft.product_id = dp.product_id\n",
    "WHERE ft.transaction_year = 2023\n",
    "GROUP BY ds.region, dp.category\n",
    "ORDER BY ds.region, total_revenue DESC;\n",
    "\n",
    "-- Query 2: Customer Loyalty Analysis\n",
    "-- Analyze purchasing patterns by loyalty tier\n",
    "SELECT \n",
    "    dc.loyalty_tier,\n",
    "    COUNT(DISTINCT dc.customer_id) as num_customers,\n",
    "    ROUND(AVG(ft.line_total), 2) as avg_purchase_amount,\n",
    "    SUM(ft.quantity) as total_items_purchased,\n",
    "    COUNT(DISTINCT ft.transaction_id) as total_transactions,\n",
    "    ROUND(SUM(ft.line_total) / COUNT(DISTINCT ft.customer_id), 2) as revenue_per_customer,\n",
    "    ROUND(COUNT(DISTINCT ft.transaction_id) / COUNT(DISTINCT ft.customer_id), 2) as avg_transactions_per_customer\n",
    "FROM dim_customer dc\n",
    "LEFT JOIN fact_transactions ft ON dc.customer_id = ft.customer_id\n",
    "WHERE ft.transaction_year = 2023\n",
    "GROUP BY dc.loyalty_tier\n",
    "ORDER BY avg_purchase_amount DESC;\n",
    "\n",
    "-- Query 3: Time-based Sales Patterns\n",
    "-- Analyze sales by hour, day, and month for better staffing and inventory\n",
    "SELECT \n",
    "    ft.transaction_hour,\n",
    "    COUNT(DISTINCT ft.transaction_id) as num_transactions,\n",
    "    ROUND(AVG(ft.line_total), 2) as avg_sale_value,\n",
    "    SUM(ft.quantity) as total_items_sold,\n",
    "    ROUND(SUM(ft.line_total), 2) as total_revenue,\n",
    "    -- Compare with average to identify peak hours\n",
    "    ROUND(SUM(ft.line_total) / AVG(SUM(ft.line_total)) OVER (), 2) as revenue_index\n",
    "FROM fact_transactions ft\n",
    "WHERE ft.transaction_year = 2023\n",
    "GROUP BY ft.transaction_hour\n",
    "ORDER BY ft.transaction_hour;\n",
    "\n",
    "-- Query 4: Monthly Sales Trends and YoY Comparison\n",
    "-- Track business growth and seasonal patterns\n",
    "WITH monthly_sales AS (\n",
    "    SELECT \n",
    "        ft.transaction_year,\n",
    "        ft.transaction_month,\n",
    "        COUNT(DISTINCT ft.transaction_id) as transactions,\n",
    "        SUM(ft.line_total) as revenue,\n",
    "        SUM(ft.quantity) as units_sold\n",
    "    FROM fact_transactions ft\n",
    "    GROUP BY ft.transaction_year, ft.transaction_month\n",
    ")\n",
    "SELECT \n",
    "    ms.transaction_year,\n",
    "    ms.transaction_month,\n",
    "    ms.transactions,\n",
    "    ROUND(ms.revenue, 2) as revenue,\n",
    "    ROUND(ms.units_sold, 2) as units_sold,\n",
    "    ROUND(LAG(ms.revenue) OVER (PARTITION BY ms.transaction_month ORDER BY ms.transaction_year), 2) as prev_year_revenue,\n",
    "    ROUND(((ms.revenue - LAG(ms.revenue) OVER (PARTITION BY ms.transaction_month ORDER BY ms.transaction_year)) / \n",
    "           LAG(ms.revenue) OVER (PARTITION BY ms.transaction_month ORDER BY ms.transaction_year)) * 100, 2) as yoy_growth_percentage\n",
    "FROM monthly_sales ms\n",
    "ORDER BY ms.transaction_year, ms.transaction_month;\n",
    "\n",
    "-- Query 5: Product Performance Analysis\n",
    "-- Identify best and worst performing products for inventory optimization\n",
    "SELECT \n",
    "    dp.category,\n",
    "    dp.product_name,\n",
    "    dp.price_range,\n",
    "    SUM(ft.quantity) as total_units_sold,\n",
    "    ROUND(SUM(ft.line_total), 2) as total_revenue,\n",
    "    COUNT(DISTINCT ft.transaction_id) as num_transactions,\n",
    "    ROUND(AVG(ft.quantity), 2) as avg_units_per_transaction,\n",
    "    -- Ranking within category\n",
    "    RANK() OVER (PARTITION BY dp.category ORDER BY SUM(ft.line_total) DESC) as rank_in_category\n",
    "FROM fact_transactions ft\n",
    "JOIN dim_product dp ON ft.product_id = dp.product_id\n",
    "WHERE ft.transaction_year = 2023\n",
    "GROUP BY dp.category, dp.product_name, dp.price_range\n",
    "HAVING SUM(ft.quantity) > 0\n",
    "ORDER BY dp.category, total_revenue DESC;\n",
    "\n",
    "-- Query 6: Store Performance Comparison\n",
    "-- Compare store performance for resource allocation\n",
    "SELECT \n",
    "    ds.store_id,\n",
    "    ds.region,\n",
    "    ds.size,\n",
    "    ds.online_store,\n",
    "    COUNT(DISTINCT ft.transaction_id) as transaction_count,\n",
    "    COUNT(DISTINCT ft.customer_id) as unique_customers,\n",
    "    ROUND(SUM(ft.line_total), 2) as total_revenue,\n",
    "    ROUND(AVG(ft.line_total), 2) as avg_transaction_value,\n",
    "    ROUND(SUM(ft.line_total) / COUNT(DISTINCT ft.transaction_id), 2) as revenue_per_transaction,\n",
    "    -- Performance percentile\n",
    "    ROUND(PERCENT_RANK() OVER (ORDER BY SUM(ft.line_total)), 2) as revenue_percentile\n",
    "FROM fact_transactions ft\n",
    "JOIN dim_store ds ON ft.store_id = ds.store_id\n",
    "WHERE ft.transaction_year = 2023\n",
    "GROUP BY ds.store_id, ds.region, ds.size, ds.online_store\n",
    "ORDER BY total_revenue DESC;\n",
    "\n",
    "-- Query 7: Customer Segmentation (RFM Analysis)\n",
    "-- Identify valuable customers for targeted marketing\n",
    "WITH customer_metrics AS (\n",
    "    SELECT \n",
    "        ft.customer_id,\n",
    "        dc.loyalty_tier,\n",
    "        dc.region,\n",
    "        DATEDIFF(MAX(ft.transaction_date), MIN(ft.transaction_date)) as customer_lifetime_days,\n",
    "        COUNT(DISTINCT ft.transaction_id) as frequency,\n",
    "        SUM(ft.line_total) as monetary_value,\n",
    "        AVG(ft.line_total) as avg_transaction_value\n",
    "    FROM fact_transactions ft\n",
    "    JOIN dim_customer dc ON ft.customer_id = dc.customer_id\n",
    "    WHERE ft.transaction_year = 2023\n",
    "    GROUP BY ft.customer_id, dc.loyalty_tier, dc.region\n",
    ")\n",
    "SELECT \n",
    "    customer_id,\n",
    "    loyalty_tier,\n",
    "    region,\n",
    "    frequency,\n",
    "    ROUND(monetary_value, 2) as total_spent,\n",
    "    ROUND(avg_transaction_value, 2) as avg_spent,\n",
    "    CASE \n",
    "        WHEN monetary_value > 1000 AND frequency > 10 THEN 'VIP'\n",
    "        WHEN monetary_value > 500 AND frequency > 5 THEN 'Regular High-Value'\n",
    "        WHEN monetary_value > 100 THEN 'Occasional'\n",
    "        ELSE 'Low Activity'\n",
    "    END as customer_segment\n",
    "FROM customer_metrics\n",
    "ORDER BY monetary_value DESC;\n",
    "\n",
    "-- Query 8: Payment Method Analysis\n",
    "-- Understand customer payment preferences\n",
    "SELECT \n",
    "    ft.payment_method,\n",
    "    COUNT(DISTINCT ft.transaction_id) as num_transactions,\n",
    "    ROUND(SUM(ft.line_total), 2) as total_processed,\n",
    "    ROUND(AVG(ft.line_total), 2) as avg_transaction_amount,\n",
    "    ROUND(COUNT(DISTINCT ft.transaction_id) * 100.0 / SUM(COUNT(DISTINCT ft.transaction_id)) OVER(), 2) as percentage_of_transactions,\n",
    "    -- Analyze by region\n",
    "    ds.region,\n",
    "    COUNT(DISTINCT ft.transaction_id) as region_transactions\n",
    "FROM fact_transactions ft\n",
    "JOIN dim_store ds ON ft.store_id = ds.store_id\n",
    "WHERE ft.transaction_year = 2023\n",
    "GROUP BY ft.payment_method, ds.region\n",
    "WITH CUBE\n",
    "ORDER BY ft.payment_method, ds.region;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9719fc34-95f7-4040-9dfa-4bbf58c6cda4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Cell 4: Create tables and load data\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Read CSV files\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m products_df \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheader\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcsv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproducts.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m customers_df \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheader\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcsv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustomers.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Register as temporary views\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "# cell_4_create_hive_tables.py\n",
    "# Convert pandas to spark dataframes\n",
    "spark_products = spark.createDataFrame(products_df)\n",
    "spark_customers = spark.createDataFrame(customers_df)\n",
    "spark_transactions = spark.createDataFrame(transactions_df)\n",
    "\n",
    "# Create database\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS retailchain_db\")\n",
    "spark.sql(\"USE retailchain_db\")\n",
    "print(\"Using database: retailchain_db\")\n",
    "\n",
    "# Create and populate tables\n",
    "spark_products.write.mode(\"overwrite\").saveAsTable(\"products\")\n",
    "spark_customers.write.mode(\"overwrite\").saveAsTable(\"customers\")\n",
    "spark_transactions.write.mode(\"overwrite\").saveAsTable(\"transactions\")\n",
    "\n",
    "print(\"Tables created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b49300a0-7196-427c-96d2-eecdef25285c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "SALES BY CATEGORY\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSALES BY CATEGORY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m result1 \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39msql(\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124m    SELECT \u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124m        p.category,\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124m        COUNT(DISTINCT t.transaction_id) as num_transactions,\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124m        SUM(t.quantity) as total_units,\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124m        ROUND(SUM(t.line_total), 2) as total_revenue,\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124m        ROUND(AVG(t.line_total), 2) as avg_transaction_value\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124m    FROM transactions t\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124m    JOIN products p ON t.product_id = p.product_id\u001b[39m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124m    GROUP BY p.category\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124m    ORDER BY total_revenue DESC\u001b[39m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m result1\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Q2: Customer loyalty analysis\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "# cell_5_run_analytics.py\n",
    "# Q1: Sales by category\n",
    "print(\"=\"*50)\n",
    "print(\"SALES BY CATEGORY\")\n",
    "print(\"=\"*50)\n",
    "result1 = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        p.category,\n",
    "        COUNT(DISTINCT t.transaction_id) as num_transactions,\n",
    "        SUM(t.quantity) as total_units,\n",
    "        ROUND(SUM(t.line_total), 2) as total_revenue,\n",
    "        ROUND(AVG(t.line_total), 2) as avg_transaction_value\n",
    "    FROM transactions t\n",
    "    JOIN products p ON t.product_id = p.product_id\n",
    "    GROUP BY p.category\n",
    "    ORDER BY total_revenue DESC\n",
    "\"\"\")\n",
    "result1.show()\n",
    "\n",
    "# Q2: Customer loyalty analysis\n",
    "print(\"=\"*50)\n",
    "print(\"CUSTOMER LOYALTY ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "result2 = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        c.loyalty_tier,\n",
    "        COUNT(DISTINCT t.customer_id) as num_customers,\n",
    "        ROUND(AVG(t.line_total), 2) as avg_purchase,\n",
    "        SUM(t.quantity) as total_items,\n",
    "        COUNT(DISTINCT t.transaction_id) as total_transactions,\n",
    "        ROUND(SUM(t.line_total) / COUNT(DISTINCT t.customer_id), 2) as revenue_per_customer\n",
    "    FROM transactions t\n",
    "    JOIN customers c ON t.customer_id = c.customer_id\n",
    "    GROUP BY c.loyalty_tier\n",
    "    ORDER BY avg_purchase DESC\n",
    "\"\"\")\n",
    "result2.show()\n",
    "\n",
    "# Q3: Monthly sales trends\n",
    "print(\"=\"*50)\n",
    "print(\"MONTHLY SALES TRENDS\")\n",
    "print(\"=\"*50)\n",
    "result3 = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        YEAR(transaction_date) as year,\n",
    "        MONTH(transaction_date) as month,\n",
    "        COUNT(DISTINCT transaction_id) as transactions,\n",
    "        ROUND(SUM(line_total), 2) as revenue,\n",
    "        COUNT(DISTINCT customer_id) as unique_customers\n",
    "    FROM transactions\n",
    "    GROUP BY YEAR(transaction_date), MONTH(transaction_date)\n",
    "    ORDER BY year, month\n",
    "\"\"\")\n",
    "result3.show()\n",
    "\n",
    "# Q4: Top products\n",
    "print(\"=\"*50)\n",
    "print(\"TOP 10 PRODUCTS BY REVENUE\")\n",
    "print(\"=\"*50)\n",
    "result4 = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        p.product_name,\n",
    "        p.category,\n",
    "        SUM(t.quantity) as units_sold,\n",
    "        ROUND(SUM(t.line_total), 2) as revenue,\n",
    "        COUNT(DISTINCT t.transaction_id) as times_purchased\n",
    "    FROM transactions t\n",
    "    JOIN products p ON t.product_id = p.product_id\n",
    "    GROUP BY p.product_name, p.category\n",
    "    ORDER BY revenue DESC\n",
    "    LIMIT 10\n",
    "\"\"\")\n",
    "result4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "860efc85-e177-4fcc-b64e-c802cdb0011d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# cell_6_create_optimized_tables.py\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Create partitioned table for better performance\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m spark\u001b[38;5;241m.\u001b[39msql(\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124m    CREATE TABLE IF NOT EXISTS transactions_partitioned\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124m    PARTITIONED BY (transaction_year INT, transaction_month INT)\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124m    STORED AS PARQUET\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124m    AS\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124m    SELECT \u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124m        transaction_id,\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124m        customer_id,\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124m        product_id,\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124m        quantity,\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124m        unit_price,\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124m        line_total,\u001b[39m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124m        payment_method,\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124m        transaction_date,\u001b[39m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124m        YEAR(transaction_date) as transaction_year,\u001b[39m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124m        MONTH(transaction_date) as transaction_month\u001b[39m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124m    FROM transactions\u001b[39m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPartitioned table created\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Create bucketed table for optimized joins\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "# cell_6_create_optimized_tables.py\n",
    "# Create partitioned table for better performance\n",
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS transactions_partitioned\n",
    "    PARTITIONED BY (transaction_year INT, transaction_month INT)\n",
    "    STORED AS PARQUET\n",
    "    AS\n",
    "    SELECT \n",
    "        transaction_id,\n",
    "        customer_id,\n",
    "        product_id,\n",
    "        quantity,\n",
    "        unit_price,\n",
    "        line_total,\n",
    "        payment_method,\n",
    "        transaction_date,\n",
    "        YEAR(transaction_date) as transaction_year,\n",
    "        MONTH(transaction_date) as transaction_month\n",
    "    FROM transactions\n",
    "\"\"\")\n",
    "print(\"Partitioned table created\")\n",
    "\n",
    "# Create bucketed table for optimized joins\n",
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS transactions_bucketed\n",
    "    CLUSTERED BY (customer_id) INTO 8 BUCKETS\n",
    "    STORED AS PARQUET\n",
    "    AS\n",
    "    SELECT * FROM transactions\n",
    "\"\"\")\n",
    "print(\"Bucketed table created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2d705dd-519a-4551-9692-0f6a56be0f19",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# cell_7_export_for_visualization.py\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Export results to CSV for visualization\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m results_to_export \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39msql(\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124m    SELECT \u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124m        p.category,\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124m        c.region,\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124m        DATE_FORMAT(t.transaction_date, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myyyy-MM\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m) as month,\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124m        SUM(t.line_total) as revenue,\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124m        SUM(t.quantity) as quantity\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124m    FROM transactions t\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124m    JOIN products p ON t.product_id = p.product_id\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124m    JOIN customers c ON t.customer_id = c.customer_id\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124m    GROUP BY p.category, c.region, DATE_FORMAT(t.transaction_date, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myyyy-MM\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124m    ORDER BY month, category, region\u001b[39m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Convert to pandas and save\u001b[39;00m\n\u001b[0;32m     18\u001b[0m results_to_export_pd \u001b[38;5;241m=\u001b[39m results_to_export\u001b[38;5;241m.\u001b[39mtoPandas()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "# cell_7_export_for_visualization.py\n",
    "# Export results to CSV for visualization\n",
    "results_to_export = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        p.category,\n",
    "        c.region,\n",
    "        DATE_FORMAT(t.transaction_date, 'yyyy-MM') as month,\n",
    "        SUM(t.line_total) as revenue,\n",
    "        SUM(t.quantity) as quantity\n",
    "    FROM transactions t\n",
    "    JOIN products p ON t.product_id = p.product_id\n",
    "    JOIN customers c ON t.customer_id = c.customer_id\n",
    "    GROUP BY p.category, c.region, DATE_FORMAT(t.transaction_date, 'yyyy-MM')\n",
    "    ORDER BY month, category, region\n",
    "\"\"\")\n",
    "\n",
    "# Convert to pandas and save\n",
    "results_to_export_pd = results_to_export.toPandas()\n",
    "results_to_export_pd.to_csv('retailchain_analytics_export.csv', index=False)\n",
    "print(\"Data exported to retailchain_analytics_export.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a887bf3-1204-4056-8229-b0ab40b36ff3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
