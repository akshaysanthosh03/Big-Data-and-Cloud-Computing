{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48512f26-76ff-4e20-8b0c-1f9fb6c954d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "139c8925-78f0-48ac-aa87-2651c6bd1399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RETAILCHAIN BIG DATA ANALYTICS DEMONSTRATION\n",
      "================================================================================\n",
      "\n",
      "[1] GENERATING SYNTHETIC RETAIL DATA...\n",
      "\n",
      "Data Generated Successfully:\n",
      "- Customers: 1,000\n",
      "- Products: 100\n",
      "- Stores: 50\n",
      "- Transactions: 10,000\n"
     ]
    }
   ],
   "source": [
    "# PART 1: Data Generation (Simulating RetailChain's Data Sources)\n",
    "class RetailChainDataGenerator:\n",
    "    \"\"\"\n",
    "    Simulates various data sources for RetailChain:\n",
    "    - Sales transactions\n",
    "    - Customer loyalty data\n",
    "    - Product information\n",
    "    - Store locations\n",
    "    - Online platform activity\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_customers=1000, num_products=100, num_stores=50, num_transactions=5000):\n",
    "        self.num_customers = num_customers\n",
    "        self.num_products = num_products\n",
    "        self.num_stores = num_stores\n",
    "        self.num_transactions = num_transactions\n",
    "        self.current_date = datetime.now()\n",
    "        \n",
    "    def generate_customer_data(self):\n",
    "        \"\"\"Generate customer loyalty program data\"\"\"\n",
    "        customer_types = ['Regular', 'Premium', 'VIP']\n",
    "        age_groups = ['18-25', '26-35', '36-50', '51-65', '65+']\n",
    "        regions = ['North', 'South', 'East', 'West', 'Central']\n",
    "        \n",
    "        customers = []\n",
    "        for i in range(1, self.num_customers + 1):\n",
    "            customer = {\n",
    "                'customer_id': f'CUST_{i:05d}',\n",
    "                'age_group': random.choice(age_groups),\n",
    "                'customer_type': random.choice(customer_types),\n",
    "                'region': random.choice(regions),\n",
    "                'loyalty_points': random.randint(0, 5000),\n",
    "                'join_date': self.current_date - timedelta(days=random.randint(1, 1095)),\n",
    "                'email_opted': random.choice([True, False]),\n",
    "                'sms_opted': random.choice([True, False])\n",
    "            }\n",
    "            customers.append(customer)\n",
    "        return pd.DataFrame(customers)\n",
    "    \n",
    "    def generate_product_data(self):\n",
    "        \"\"\"Generate product catalog data\"\"\"\n",
    "        categories = ['Electronics', 'Clothing', 'Home & Garden', 'Sports', 'Books', 'Food', 'Beauty']\n",
    "        subcategories = {\n",
    "            'Electronics': ['Laptops', 'Smartphones', 'Accessories', 'TVs', 'Audio'],\n",
    "            'Clothing': ['Men', 'Women', 'Kids', 'Footwear', 'Accessories'],\n",
    "            'Home & Garden': ['Furniture', 'Decor', 'Kitchen', 'Garden', 'Tools'],\n",
    "            'Sports': ['Fitness', 'Outdoor', 'Team Sports', 'Water Sports', 'Cycling'],\n",
    "            'Books': ['Fiction', 'Non-fiction', 'Educational', 'Children', 'Magazines'],\n",
    "            'Food': ['Groceries', 'Snacks', 'Beverages', 'Organic', 'International'],\n",
    "            'Beauty': ['Skincare', 'Makeup', 'Haircare', 'Fragrance', 'Personal Care']\n",
    "        }\n",
    "        \n",
    "        products = []\n",
    "        for i in range(1, self.num_products + 1):\n",
    "            category = random.choice(categories)\n",
    "            product = {\n",
    "                'product_id': f'PROD_{i:04d}',\n",
    "                'product_name': f'Product_{i}',\n",
    "                'category': category,\n",
    "                'subcategory': random.choice(subcategories[category]),\n",
    "                'unit_price': round(random.uniform(5, 500), 2),\n",
    "                'cost_price': round(random.uniform(3, 400), 2),\n",
    "                'supplier': f'SUPP_{random.randint(1, 20):02d}',\n",
    "                'stock_level': random.randint(0, 1000)\n",
    "            }\n",
    "            products.append(product)\n",
    "        return pd.DataFrame(products)\n",
    "    \n",
    "    def generate_store_data(self):\n",
    "        \"\"\"Generate store location data\"\"\"\n",
    "        store_types = ['Mall', 'High Street', 'Retail Park', 'Online Only']\n",
    "        \n",
    "        stores = []\n",
    "        for i in range(1, self.num_stores + 1):\n",
    "            store = {\n",
    "                'store_id': f'STORE_{i:03d}',\n",
    "                'store_type': random.choice(store_types),\n",
    "                'region': random.choice(['North', 'South', 'East', 'West', 'Central']),\n",
    "                'size_sqft': random.randint(1000, 50000),\n",
    "                'opening_date': self.current_date - timedelta(days=random.randint(1, 1825)),\n",
    "                'online_capacity': random.choice([True, False])\n",
    "            }\n",
    "            stores.append(store)\n",
    "        return pd.DataFrame(stores)\n",
    "    \n",
    "    def generate_transaction_data(self, customers_df, products_df, stores_df):\n",
    "        \"\"\"Generate sales transaction data\"\"\"\n",
    "        transactions = []\n",
    "        payment_methods = ['Credit Card', 'Debit Card', 'Cash', 'Gift Card', 'Mobile Payment']\n",
    "        channels = ['In-Store', 'Online', 'Mobile App']\n",
    "        \n",
    "        for i in range(1, self.num_transactions + 1):\n",
    "            # Random date within last 6 months\n",
    "            transaction_date = self.current_date - timedelta(days=random.randint(1, 180))\n",
    "            \n",
    "            transaction = {\n",
    "                'transaction_id': f'TRX_{i:06d}',\n",
    "                'customer_id': random.choice(customers_df['customer_id']),\n",
    "                'store_id': random.choice(stores_df['store_id']),\n",
    "                'product_id': random.choice(products_df['product_id']),\n",
    "                'transaction_date': transaction_date,\n",
    "                'quantity': random.randint(1, 5),\n",
    "                'payment_method': random.choice(payment_methods),\n",
    "                'channel': random.choice(channels),\n",
    "                'discount_applied': random.choice([0, 0, 0, 0.1, 0.15, 0.2])  # More zeros for no discount\n",
    "            }\n",
    "            transactions.append(transaction)\n",
    "        \n",
    "        transactions_df = pd.DataFrame(transactions)\n",
    "        \n",
    "        # Merge with product prices\n",
    "        transactions_df = transactions_df.merge(\n",
    "            products_df[['product_id', 'unit_price', 'cost_price', 'category']], \n",
    "            on='product_id', \n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        # Calculate actual price after discount\n",
    "        transactions_df['actual_price'] = transactions_df['unit_price'] * (1 - transactions_df['discount_applied'])\n",
    "        transactions_df['revenue'] = transactions_df['actual_price'] * transactions_df['quantity']\n",
    "        transactions_df['profit'] = (transactions_df['actual_price'] - transactions_df['cost_price']) * transactions_df['quantity']\n",
    "        \n",
    "        return transactions_df\n",
    "\n",
    "# Generate the data\n",
    "print(\"=\" * 80)\n",
    "print(\"RETAILCHAIN BIG DATA ANALYTICS DEMONSTRATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "generator = RetailChainDataGenerator(\n",
    "    num_customers=1000,\n",
    "    num_products=100,\n",
    "    num_stores=50,\n",
    "    num_transactions=10000\n",
    ")\n",
    "\n",
    "print(\"\\n[1] GENERATING SYNTHETIC RETAIL DATA...\")\n",
    "customers_df = generator.generate_customer_data()\n",
    "products_df = generator.generate_product_data()\n",
    "stores_df = generator.generate_store_data()\n",
    "transactions_df = generator.generate_transaction_data(customers_df, products_df, stores_df)\n",
    "\n",
    "print(f\"\\nData Generated Successfully:\")\n",
    "print(f\"- Customers: {len(customers_df):,}\")\n",
    "print(f\"- Products: {len(products_df):,}\")\n",
    "print(f\"- Stores: {len(stores_df):,}\")\n",
    "print(f\"- Transactions: {len(transactions_df):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5622eaa-1286-4bfa-8027-3e42a2c02000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[2] PERFORMING SALES ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Overall Sales Metrics:\n",
      "- Total Revenue: £6,384,078.60\n",
      "- Total Profit: £420,502.75\n",
      "- Average Transaction Value: £638.41\n",
      "\n",
      "Category Performance:\n",
      "                  Revenue     Profit  Units Sold  Transaction Count  Profit Margin %\n",
      "category                                                                            \n",
      "Electronics    1573651.89  233292.24        6834               2302            14.82\n",
      "Food           1265987.99  477515.32        5012               1710            37.72\n",
      "Sports         1015511.52  224194.12        4455               1513            22.08\n",
      "Clothing        783598.90  276564.91        3046               1027            35.29\n",
      "Books           717985.37 -336938.66        4745               1583           -46.93\n",
      "Beauty          584175.63 -354766.70        3138               1039           -60.73\n",
      "Home & Garden   443167.30  -99358.48        2479                826           -22.42\n",
      "\n",
      "================================================================================\n",
      "[3] PERFORMING CUSTOMER ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Customer Segmentation Summary:\n",
      "Segment\n",
      "Platinum    973\n",
      "Gold         25\n",
      "Silver        0\n",
      "Bronze        0\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Regional Performance:\n",
      "         Total_Revenue  Total_Transactions  Unique_Customers\n",
      "region                                                      \n",
      "Central     1245962.68                1959               197\n",
      "East        1281986.34                2029               203\n",
      "North       1308554.92                2044               200\n",
      "South       1337230.67                2121               211\n",
      "West        1210343.98                1847               187\n",
      "\n",
      "================================================================================\n",
      "[4] PERFORMING TIME SERIES ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Average Daily Sales by Day of Week:\n",
      "- Sunday: £652.67\n",
      "- Monday: £644.84\n",
      "- Friday: £642.85\n",
      "- Tuesday: £636.23\n",
      "- Saturday: £634.04\n",
      "- Thursday: £630.59\n",
      "- Wednesday: £627.25\n",
      "\n",
      "Monthly Sales Trend:\n",
      "- August 2025: £381,461.09\n",
      "- September 2025: £1,050,517.03\n",
      "- October 2025: £1,073,538.71\n",
      "- November 2025: £1,075,729.03\n",
      "- December 2025: £1,034,078.11\n",
      "- January 2026: £1,162,283.10\n",
      "- February 2026: £606,471.53\n",
      "\n",
      "================================================================================\n",
      "[5] PERFORMING INVENTORY ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Inventory Metrics:\n",
      "- Total Inventory Value: £10,757,086.34\n",
      "- Average Sell-through Rate: 46.9%\n",
      "\n",
      "Slow-moving Products (Sell-through < 10%): 0 products\n",
      "- Total Value of Slow-moving Stock: £0.00\n"
     ]
    }
   ],
   "source": [
    "# PART 2: Data Processing and Analytics Workflow\n",
    "\n",
    "class RetailAnalyticsProcessor:\n",
    "    \"\"\"\n",
    "    Processes retail data to generate business insights\n",
    "    Demonstrates batch processing approach for big data analytics\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, transactions_df, customers_df, products_df, stores_df):\n",
    "        self.transactions = transactions_df\n",
    "        self.customers = customers_df\n",
    "        self.products = products_df\n",
    "        self.stores = stores_df\n",
    "        \n",
    "    def perform_sales_analysis(self):\n",
    "        \"\"\"Analyze sales trends and patterns\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"[2] PERFORMING SALES ANALYSIS\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Overall sales metrics\n",
    "        total_revenue = self.transactions['revenue'].sum()\n",
    "        total_profit = self.transactions['profit'].sum()\n",
    "        avg_transaction_value = self.transactions.groupby('transaction_id')['revenue'].sum().mean()\n",
    "        \n",
    "        print(f\"\\nOverall Sales Metrics:\")\n",
    "        print(f\"- Total Revenue: £{total_revenue:,.2f}\")\n",
    "        print(f\"- Total Profit: £{total_profit:,.2f}\")\n",
    "        print(f\"- Average Transaction Value: £{avg_transaction_value:,.2f}\")\n",
    "        \n",
    "        # Category performance\n",
    "        category_performance = self.transactions.groupby('category').agg({\n",
    "            'revenue': 'sum',\n",
    "            'profit': 'sum',\n",
    "            'quantity': 'sum',\n",
    "            'transaction_id': 'count'\n",
    "        }).round(2)\n",
    "        category_performance.columns = ['Revenue', 'Profit', 'Units Sold', 'Transaction Count']\n",
    "        category_performance['Profit Margin %'] = (category_performance['Profit'] / category_performance['Revenue'] * 100).round(2)\n",
    "        category_performance = category_performance.sort_values('Revenue', ascending=False)\n",
    "        \n",
    "        print(\"\\nCategory Performance:\")\n",
    "        print(category_performance.to_string())\n",
    "        \n",
    "        return category_performance\n",
    "    \n",
    "    def perform_customer_analysis(self):\n",
    "        \"\"\"Analyze customer behavior and segmentation\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"[3] PERFORMING CUSTOMER ANALYSIS\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Customer lifetime value metrics\n",
    "        customer_metrics = self.transactions.groupby('customer_id').agg({\n",
    "            'revenue': ['sum', 'count', 'mean'],\n",
    "            'profit': 'sum'\n",
    "        }).round(2)\n",
    "        customer_metrics.columns = ['Total_Spend', 'Transaction_Count', 'Avg_Transaction', 'Total_Profit']\n",
    "        \n",
    "        # Merge with customer demographics\n",
    "        customer_analysis = customer_metrics.merge(\n",
    "            self.customers[['customer_id', 'age_group', 'region', 'customer_type']], \n",
    "            left_index=True, \n",
    "            right_on='customer_id'\n",
    "        )\n",
    "        \n",
    "        # Customer segmentation (RFM - Recency, Frequency, Monetary)\n",
    "        latest_date = self.transactions['transaction_date'].max()\n",
    "        rfm = self.transactions.groupby('customer_id').agg({\n",
    "            'transaction_date': lambda x: (latest_date - x.max()).days,  # Recency\n",
    "            'transaction_id': 'count',  # Frequency\n",
    "            'revenue': 'sum'  # Monetary\n",
    "        }).round(2)\n",
    "        rfm.columns = ['Recency', 'Frequency', 'Monetary']\n",
    "        \n",
    "        # Segment customers\n",
    "        rfm['Segment'] = pd.cut(rfm['Monetary'], \n",
    "                                bins=[0, 100, 500, 2000, float('inf')],\n",
    "                                labels=['Bronze', 'Silver', 'Gold', 'Platinum'])\n",
    "        \n",
    "        print(f\"\\nCustomer Segmentation Summary:\")\n",
    "        print(rfm['Segment'].value_counts())\n",
    "        \n",
    "        # Regional analysis\n",
    "        regional_analysis = customer_analysis.groupby('region').agg({\n",
    "            'Total_Spend': 'sum',\n",
    "            'Transaction_Count': 'sum',\n",
    "            'customer_id': 'nunique'\n",
    "        }).round(2)\n",
    "        regional_analysis.columns = ['Total_Revenue', 'Total_Transactions', 'Unique_Customers']\n",
    "        \n",
    "        print(\"\\nRegional Performance:\")\n",
    "        print(regional_analysis.to_string())\n",
    "        \n",
    "        return rfm, customer_analysis, regional_analysis\n",
    "    \n",
    "    def perform_time_series_analysis(self):\n",
    "        \"\"\"Analyze temporal patterns in sales\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"[4] PERFORMING TIME SERIES ANALYSIS\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Daily sales trends\n",
    "        daily_sales = self.transactions.groupby(\n",
    "            pd.Grouper(key='transaction_date', freq='D')\n",
    "        )['revenue'].sum().reset_index()\n",
    "        daily_sales.columns = ['Date', 'Daily_Revenue']\n",
    "        \n",
    "        # Weekly patterns\n",
    "        self.transactions['day_of_week'] = pd.to_datetime(self.transactions['transaction_date']).dt.day_name()\n",
    "        daily_pattern = self.transactions.groupby('day_of_week')['revenue'].mean().sort_values(ascending=False)\n",
    "        \n",
    "        print(\"\\nAverage Daily Sales by Day of Week:\")\n",
    "        for day, revenue in daily_pattern.items():\n",
    "            print(f\"- {day}: £{revenue:,.2f}\")\n",
    "        \n",
    "        # Monthly trends\n",
    "        monthly_sales = self.transactions.groupby(\n",
    "            pd.Grouper(key='transaction_date', freq='M')\n",
    "        )['revenue'].sum().reset_index()\n",
    "        monthly_sales.columns = ['Month', 'Monthly_Revenue']\n",
    "        \n",
    "        print(f\"\\nMonthly Sales Trend:\")\n",
    "        for _, row in monthly_sales.iterrows():\n",
    "            print(f\"- {row['Month'].strftime('%B %Y')}: £{row['Monthly_Revenue']:,.2f}\")\n",
    "        \n",
    "        return daily_sales, daily_pattern, monthly_sales\n",
    "    \n",
    "    def perform_inventory_analysis(self):\n",
    "        \"\"\"Analyze inventory performance and optimization opportunities\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"[5] PERFORMING INVENTORY ANALYSIS\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Product performance\n",
    "        product_performance = self.transactions.groupby('product_id').agg({\n",
    "            'quantity': 'sum',\n",
    "            'revenue': 'sum',\n",
    "            'profit': 'sum'\n",
    "        }).round(2)\n",
    "        \n",
    "        # Merge with product details\n",
    "        product_analysis = product_performance.merge(\n",
    "            self.products[['product_id', 'product_name', 'category', 'stock_level', 'unit_price']],\n",
    "            on='product_id'\n",
    "        )\n",
    "        \n",
    "        # Calculate sell-through rate and days of inventory\n",
    "        product_analysis['sell_through_rate'] = (\n",
    "            product_analysis['quantity'] / (product_analysis['stock_level'] + product_analysis['quantity'])\n",
    "        ).round(3)\n",
    "        \n",
    "        product_analysis['inventory_value'] = product_analysis['stock_level'] * product_analysis['unit_price']\n",
    "        \n",
    "        print(f\"\\nInventory Metrics:\")\n",
    "        print(f\"- Total Inventory Value: £{product_analysis['inventory_value'].sum():,.2f}\")\n",
    "        print(f\"- Average Sell-through Rate: {product_analysis['sell_through_rate'].mean():.1%}\")\n",
    "        \n",
    "        # Identify slow-moving products\n",
    "        slow_moving = product_analysis[product_analysis['sell_through_rate'] < 0.1].sort_values('inventory_value', ascending=False)\n",
    "        \n",
    "        print(f\"\\nSlow-moving Products (Sell-through < 10%): {len(slow_moving)} products\")\n",
    "        print(f\"- Total Value of Slow-moving Stock: £{slow_moving['inventory_value'].sum():,.2f}\")\n",
    "        \n",
    "        return product_analysis, slow_moving\n",
    "\n",
    "# Initialize processor\n",
    "processor = RetailAnalyticsProcessor(transactions_df, customers_df, products_df, stores_df)\n",
    "\n",
    "# Perform analyses\n",
    "category_performance = processor.perform_sales_analysis()\n",
    "rfm, customer_analysis, regional_analysis = processor.perform_customer_analysis()\n",
    "daily_sales, daily_pattern, monthly_sales = processor.perform_time_series_analysis()\n",
    "product_analysis, slow_moving = processor.perform_inventory_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8145e83-de88-44f6-950d-fd6f112301e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 3: Predictive Analytics (Machine Learning)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"[6] PREDICTIVE ANALYTICS - SALES FORECASTING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "class SalesForecastingModel:\n",
    "    \"\"\"\n",
    "    Implements a machine learning model to predict future sales\n",
    "    Demonstrates advanced analytics capabilities\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, transactions_df, products_df):\n",
    "        self.transactions = transactions_df\n",
    "        self.products = products_df\n",
    "        self.model = None\n",
    "        \n",
    "    def prepare_features(self):\n",
    "        \"\"\"Prepare features for sales prediction\"\"\"\n",
    "        # Aggregate daily sales by category\n",
    "        daily_category_sales = self.transactions.groupby([\n",
    "            pd.Grouper(key='transaction_date', freq='D'),\n",
    "            'category'\n",
    "        ])['revenue'].sum().reset_index()\n",
    "        \n",
    "        # Create time-based features\n",
    "        daily_category_sales['day_of_week'] = pd.to_datetime(daily_category_sales['transaction_date']).dt.dayofweek\n",
    "        daily_category_sales['month'] = pd.to_datetime(daily_category_sales['transaction_date']).dt.month\n",
    "        daily_category_sales['quarter'] = pd.to_datetime(daily_category_sales['transaction_date']).dt.quarter\n",
    "        daily_category_sales['is_weekend'] = daily_category_sales['day_of_week'].isin([5, 6]).astype(int)\n",
    "        \n",
    "        # Create lag features\n",
    "        for lag in [1, 7, 30]:  # Previous day, week, month\n",
    "            daily_category_sales[f'lag_{lag}_days'] = daily_category_sales.groupby('category')['revenue'].shift(lag)\n",
    "        \n",
    "        # Drop rows with NaN values\n",
    "        daily_category_sales = daily_category_sales.dropna()\n",
    "        \n",
    "        return daily_category_sales\n",
    "    \n",
    "    def train_model(self, category_name):\n",
    "        \"\"\"Train a Random Forest model for a specific category\"\"\"\n",
    "        data = self.prepare_features()\n",
    "        category_data = data[data['category'] == category_name].copy()\n",
    "        \n",
    "        # Define features and target\n",
    "        feature_columns = ['day_of_week', 'month', 'quarter', 'is_weekend', 'lag_1_days', 'lag_7_days', 'lag_30_days']\n",
    "        X = category_data[feature_columns]\n",
    "        y = category_data['revenue']\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Train model\n",
    "        self.model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        self.model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        \n",
    "        # Evaluate model\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        print(f\"\\nCategory: {category_name}\")\n",
    "        print(f\"Model Performance:\")\n",
    "        print(f\"- Mean Absolute Error: £{mae:,.2f}\")\n",
    "        print(f\"- R² Score: {r2:.3f}\")\n",
    "        print(f\"- Feature Importance:\")\n",
    "        \n",
    "        for feature, importance in zip(feature_columns, self.model.feature_importances_):\n",
    "            print(f\"  * {feature}: {importance:.3f}\")\n",
    "        \n",
    "        return self.model, mae, r2\n",
    "\n",
    "# Train forecasting model for Electronics category\n",
    "forecaster = SalesForecastingModel(transactions_df, products_df)\n",
    "electronics_model, mae, r2 = forecaster.train_model('Electronics')\n",
    "\n",
    "# ============================================\n",
    "# PART 4: VISUALIZATIONS\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"[7] GENERATING BUSINESS INTELLIGENCE DASHBOARD\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create a comprehensive visualization dashboard\n",
    "fig = plt.figure(figsize=(20, 15))\n",
    "\n",
    "# 1. Sales by Category (Pie Chart)\n",
    "ax1 = plt.subplot(3, 3, 1)\n",
    "category_revenue = transactions_df.groupby('category')['revenue'].sum()\n",
    "colors = sns.color_palette('husl', len(category_revenue))\n",
    "plt.pie(category_revenue.values, labels=category_revenue.index, autopct='%1.1f%%', colors=colors)\n",
    "plt.title('Revenue by Product Category', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 2. Daily Sales Trend\n",
    "ax2 = plt.subplot(3, 3, 2)\n",
    "daily_sales_sorted = daily_sales.sort_values('Date')\n",
    "plt.plot(daily_sales_sorted['Date'], daily_sales_sorted['Daily_Revenue'], marker='o', linewidth=2, markersize=4)\n",
    "plt.title('Daily Sales Trend', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Revenue (£)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# 3. Sales by Day of Week\n",
    "ax3 = plt.subplot(3, 3, 3)\n",
    "days_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "daily_pattern_ordered = daily_pattern.reindex(days_order)\n",
    "bars = plt.bar(daily_pattern_ordered.index, daily_pattern_ordered.values)\n",
    "plt.title('Average Sales by Day of Week', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Average Revenue (£)')\n",
    "plt.xticks(rotation=45)\n",
    "for bar, value in zip(bars, daily_pattern_ordered.values):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 50, f'£{value:.0f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# 4. Customer Segmentation\n",
    "ax4 = plt.subplot(3, 3, 4)\n",
    "segment_counts = rfm['Segment'].value_counts()\n",
    "colors_segment = ['#FFD700' if x == 'Platinum' else '#C0C0C0' if x == 'Gold' else '#CD7F32' if x == 'Silver' else '#8C7853' for x in segment_counts.index]\n",
    "plt.bar(segment_counts.index, segment_counts.values, color=colors_segment)\n",
    "plt.title('Customer Segmentation', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Segment')\n",
    "plt.ylabel('Number of Customers')\n",
    "for i, (idx, val) in enumerate(segment_counts.items()):\n",
    "    plt.text(i, val + 10, str(val), ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 5. Regional Performance\n",
    "ax5 = plt.subplot(3, 3, 5)\n",
    "regional_revenue = transactions_df.groupby(transactions_df.merge(stores_df, on='store_id')['region'])['revenue'].sum()\n",
    "plt.bar(regional_revenue.index, regional_revenue.values, color=sns.color_palette('viridis', len(regional_revenue)))\n",
    "plt.title('Revenue by Region', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Region')\n",
    "plt.ylabel('Revenue (£)')\n",
    "for i, (region, revenue) in enumerate(regional_revenue.items()):\n",
    "    plt.text(i, revenue + 5000, f'£{revenue/1000:.0f}K', ha='center', va='bottom')\n",
    "\n",
    "# 6. Payment Method Distribution\n",
    "ax6 = plt.subplot(3, 3, 6)\n",
    "payment_counts = transactions_df['payment_method'].value_counts()\n",
    "plt.pie(payment_counts.values, labels=payment_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Payment Method Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 7. Profit Margin by Category\n",
    "ax7 = plt.subplot(3, 3, 7)\n",
    "profit_margins = category_performance['Profit Margin %']\n",
    "bars = plt.bar(profit_margins.index, profit_margins.values, color=sns.color_palette('RdYlGn', len(profit_margins)))\n",
    "plt.title('Profit Margin by Category', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Profit Margin (%)')\n",
    "plt.xticks(rotation=45)\n",
    "for bar, value in zip(bars, profit_margins.values):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, f'{value:.1f}%', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# 8. Channel Performance\n",
    "ax8 = plt.subplot(3, 3, 8)\n",
    "channel_revenue = transactions_df.groupby('channel')['revenue'].sum()\n",
    "bars = plt.bar(channel_revenue.index, channel_revenue.values, color=sns.color_palette('pastel', len(channel_revenue)))\n",
    "plt.title('Revenue by Sales Channel', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Channel')\n",
    "plt.ylabel('Revenue (£)')\n",
    "for i, (channel, revenue) in enumerate(channel_revenue.items()):\n",
    "    plt.text(i, revenue + 10000, f'£{revenue/1000:.0f}K', ha='center', va='bottom')\n",
    "\n",
    "# 9. Top Selling Products\n",
    "ax9 = plt.subplot(3, 3, 9)\n",
    "top_products = transactions_df.groupby('product_id')['quantity'].sum().sort_values(ascending=False).head(10)\n",
    "top_products_names = [f'PROD_{i+1}' for i in range(10)]\n",
    "plt.barh(range(10), top_products.values, color='green', alpha=0.7)\n",
    "plt.yticks(range(10), [f'Product {i+1}' for i in range(10)])\n",
    "plt.title('Top 10 Selling Products', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Quantity Sold')\n",
    "\n",
    "plt.suptitle('RETAILCHAIN BUSINESS INTELLIGENCE DASHBOARD', fontsize=18, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('retailchain_dashboard.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"\\nDashboard saved as 'retailchain_dashboard.png'\")\n",
    "\n",
    "# ============================================\n",
    "# PART 5: KEY INSIGHTS AND RECOMMENDATIONS\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"[8] BUSINESS INSIGHTS AND RECOMMENDATIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Calculate key metrics\n",
    "total_customers = len(customers_df)\n",
    "active_customers = transactions_df['customer_id'].nunique()\n",
    "avg_order_value = transactions_df.groupby('transaction_id')['revenue'].sum().mean()\n",
    "repeat_rate = (transactions_df.groupby('customer_id')['transaction_id'].count() > 1).mean() * 100\n",
    "\n",
    "print(f\"\"\"\n",
    "KEY PERFORMANCE INDICATORS (KPIs):\n",
    "----------------------------------\n",
    "Total Customers: {total_customers:,}\n",
    "Active Customers (with purchases): {active_customers:,}\n",
    "Customer Engagement Rate: {(active_customers/total_customers*100):.1f}%\n",
    "Average Order Value: £{avg_order_value:.2f}\n",
    "Customer Repeat Rate: {repeat_rate:.1f}%\n",
    "\"\"\")\n",
    "\n",
    "print(\"STRATEGIC INSIGHTS:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Insight 1: Category Performance\n",
    "top_category = category_performance.index[0]\n",
    "print(f\"1. Electronics is the top-performing category, generating £{category_performance.loc['Electronics', 'Revenue']:,.2f} in revenue. Consider expanding this category and optimizing inventory for electronics products.\")\n",
    "\n",
    "# Insight 2: Customer Segmentation\n",
    "platinum_customers = (rfm['Segment'] == 'Platinum').sum()\n",
    "print(f\"2. Platinum customers represent only {platinum_customers/len(rfm)*100:.1f}% of customers but generate the highest value. Implement a targeted loyalty program to retain these high-value customers.\")\n",
    "\n",
    "# Insight 3: Channel Strategy\n",
    "online_revenue = transactions_df[transactions_df['channel'].isin(['Online', 'Mobile App'])]['revenue'].sum()\n",
    "total_revenue = transactions_df['revenue'].sum()\n",
    "print(f\"3. Digital channels (Online + Mobile App) account for £{online_revenue:,.2f} ({online_revenue/total_revenue*100:.1f}% of total revenue). Invest in mobile app improvements and personalization.\")\n",
    "\n",
    "# Insight 4: Inventory Management\n",
    "slow_moving_count = len(slow_moving)\n",
    "print(f\"4. {slow_moving_count} products are slow-moving with sell-through rates below 10%. These represent £{slow_moving['inventory_value'].sum():,.2f} in tied-up capital. Implement clearance strategies or supplier negotiations.\")\n",
    "\n",
    "# Insight 5: Time-based Patterns\n",
    "best_day = daily_pattern.idxmax()\n",
    "print(f\"5. {best_day} shows the highest average sales. Schedule marketing campaigns and promotions on {best_day}s to maximize impact.\")\n",
    "\n",
    "# Insight 6: Regional Opportunities\n",
    "top_region = regional_revenue.idxmax()\n",
    "bottom_region = regional_revenue.idxmin()\n",
    "print(f\"6. {top_region} region leads in sales, while {bottom_region} region underperforms. Investigate regional preferences and consider targeted marketing in underperforming regions.\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"=\" * 80)\n",
    "print(\"RECOMMENDED ACTIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "recommendations = [\n",
    "    \"1. Implement Real-time Inventory Management System to prevent stockouts of top-selling products\",\n",
    "    \"2. Develop Personalized Marketing Campaigns based on customer segmentation and purchase history\",\n",
    "    \"3. Optimize Store Layout and Staffing based on peak hours and days identified in time series analysis\",\n",
    "    \"4. Launch Mobile App with AI-powered recommendations to boost digital channel revenue\",\n",
    "    \"5. Implement Dynamic Pricing Strategy for slow-moving products to clear inventory\",\n",
    "    \"6. Create Regional Marketing Teams to address local preferences and market conditions\",\n",
    "    \"7. Establish Supplier Scorecards based on product performance and sell-through rates\",\n",
    "    \"8. Develop Customer Loyalty Program with tiered benefits to encourage repeat purchases\"\n",
    "]\n",
    "\n",
    "for rec in recommendations:\n",
    "    print(rec)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DATA ARCHITECTURE RECOMMENDATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\"\"\n",
    "Based on the analysis, the recommended big data architecture for RetailChain:\n",
    "\n",
    "┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐\n",
    "│   DATA SOURCES  │───▶│  INGESTION      │───▶│  STORAGE        │\n",
    "│ • POS Systems   │    │ • Apache Kafka  │    │ • Data Lake     │\n",
    "│ • E-commerce    │    │ • AWS Kinesis   │    │   (Raw data)    │\n",
    "│ • Loyalty App   │    │ • Batch ETL     │    │ • Data Warehouse│\n",
    "│ • Supplier DB   │    │                 │    │   (Processed)   │\n",
    "└─────────────────┘    └─────────────────┘    └─────────────────┘\n",
    "                              │                         │\n",
    "                              ▼                         ▼\n",
    "┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐\n",
    "│   VISUALIZATION │◀───│  PROCESSING     │◀───│  COMPUTE        │\n",
    "│ • Power BI      │    │ • Spark         │    │ • AWS EMR       │\n",
    "│ • Tableau       │    │ • Python        │    │ • Databricks    │\n",
    "│ • Custom Dash   │    │ • ML Models     │    │ • Lambda        │\n",
    "└─────────────────┘    └─────────────────┘    └─────────────────┘\n",
    "\n",
    "Key Components:\n",
    "1. Batch Processing Layer: Apache Spark for daily sales aggregations and customer analytics\n",
    "2. Stream Processing: Apache Kafka for real-time inventory updates and fraud detection\n",
    "3. Storage: Data Lake (S3/ADLS) for raw data + Warehouse (Redshift/Synapse) for structured analytics\n",
    "4. ML Platform: Databricks for model training and deployment\n",
    "5. Visualization: Power BI/Tableau for executive dashboards\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"REFLECTION AND FUTURE ENHANCEMENTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\"\"\n",
    "REFLECTION:\n",
    "This demonstration successfully illustrates how RetailChain can leverage big data analytics\n",
    "to drive business decisions. Key learnings include:\n",
    "\n",
    "1. Data Integration: Combining multiple data sources (sales, customer, product) provides\n",
    "   holistic insights not possible from siloed systems.\n",
    "\n",
    "2. Analytics Value: Descriptive analytics (what happened) and predictive analytics\n",
    "   (what will happen) both provide actionable business intelligence.\n",
    "\n",
    "3. Technical Considerations: The choice between batch and real-time processing depends\n",
    "   on the business question - daily sales reports vs real-time inventory alerts.\n",
    "\n",
    "CHALLENGES ENCOUNTERED:\n",
    "- Data Quality: Synthetic data required careful validation to ensure realistic patterns\n",
    "- Feature Engineering: Creating meaningful features for ML models required domain knowledge\n",
    "- Scalability: The current implementation would need distributed computing for production scale\n",
    "\n",
    "FUTURE ENHANCEMENTS:\n",
    "1. Real-time Analytics: Implement streaming analytics for live inventory tracking\n",
    "2. Advanced ML: Deploy recommendation engines using collaborative filtering\n",
    "3. IoT Integration: Incorporate sensor data from stores for footfall analysis\n",
    "4. Natural Language Processing: Analyze customer reviews and feedback\n",
    "5. Graph Analytics: Map customer-product relationships for cross-selling opportunities\n",
    "\n",
    "SCALING RECOMMENDATIONS:\n",
    "To scale this solution for production:\n",
    "- Migrate to cloud platform (AWS/Azure/GCP)\n",
    "- Implement distributed data processing with Apache Spark\n",
    "- Use containerization (Docker/Kubernetes) for model deployment\n",
    "- Establish data governance framework with clear ownership and quality standards\n",
    "- Implement CI/CD pipeline for analytics code deployment\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DEMONSTRATION COMPLETE\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
